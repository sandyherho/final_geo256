


# Import pygmt for creating maps and processing geospatial data, leveraging the Generic Mapping Tools (GMT).
import pygmt

# Import numpy as np for numerical operations on arrays and matrices, widely used for scientific computing.
import numpy as np

# Import pandas as pd for data manipulation and analysis, particularly useful for handling structured data.
import pandas as pd

# Import pyplot from matplotlib as plt for creating static, interactive, and animated visualizations in Python.
import matplotlib.pyplot as plt

# Import seaborn as sns for statistical data visualization, built on top of matplotlib and closely integrated with pandas data structures.
import seaborn as sns

# From the scipy library, import stats module for a large number of probability distributions and statistical functions.
from scipy import stats

# From statsmodels' tsa.stattools, import adfuller and kpss for statistical tests that can be used to check the stationarity of a time series.
# adfuller: Augmented Dickey-Fuller unit root test.
# kpss: Kwiatkowski-Phillips-Schmidt-Shin test for stationarity.
from statsmodels.tsa.stattools import adfuller, kpss

# From statsmodels' graphics.tsaplots, import plot_acf and plot_pacf for plotting the autocorrelation and partial autocorrelation functions,
# useful in the analysis of time series data.
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Import EVA (Extreme Value Analysis), get_extremes, and get_return_periods from pyextremes for analyzing and modeling extreme values in data.
from pyextremes import EVA, get_extremes, get_return_periods

# Import TabularDataset and TabularPredictor from autogluon.tabular for automated machine learning on tabular data.
# TabularDataset: For loading and pre-processing structured data.
# TabularPredictor: For training machine learning models and making predictions.
from autogluon.tabular import TabularDataset, TabularPredictor

# Set the plotting style to 'bmh' (Bayesian Methods for Hackers:  Davidson-Pilon(2015)) using matplotlib. This style is suited for visualizations within
# Bayesian frameworks but is widely applicable for its clean and readable presentation.
plt.style.use("bmh")





class SRTMMapPlotter:
    """
    A class to encapsulate the process of loading, plotting, and saving SRTM15+ Earth relief data using PyGMT.

    Attributes:
        region (list): The geographical region to plot specified as [west, east, south, north].
        resolution (str): The resolution of the Earth relief data. Default is "15s".
        grid (xarray.DataArray): The loaded Earth relief data for the specified region.
        figure (pygmt.Figure): The PyGMT figure object for plotting.

    Methods:
        load_data(): Loads the Earth relief data based on the specified region and resolution.
        plot_map(): Plots the Earth relief data as a map.
        plot_marker(x, y, style, fill): Marks a specific point on the map.
        add_colorbar(frame): Adds a colorbar to the map.
        show(): Displays the figure in an interactive window.
        save(filename, dpi): Saves the figure to a file with the specified resolution.
    """
    def __init__(self, region, resolution="15s"):
        """
        Initializes the SRTMMapPlotter object with a specified region and resolution.

        Parameters:
            region (list): The geographical region to plot specified as [west, east, south, north].
            resolution (str): The resolution of the Earth relief data. Default is "15s".
        """
        self.region = region
        self.resolution = resolution
        self.grid = self.load_data()
        self.figure = pygmt.Figure()

    def load_data(self):
        """
        Loads the Earth relief data for the specified region and resolution.

        Returns:
            xarray.DataArray: The loaded Earth relief data.
        """
        return pygmt.datasets.load_earth_relief(resolution=self.resolution, region=self.region)

    def plot_map(self):
        """
        Plots the Earth relief data as a map using the loaded grid data.
        """
        self.figure.grdimage(grid=self.grid, projection="M15c", frame="a", cmap="geo")

    def plot_marker(self, x, y, style="c0.3c", fill="red"):
        """
        Marks a specific point on the map with a marker.

        Parameters:
            x (float): The longitude of the point to mark.
            y (float): The latitude of the point to mark.
            style (str): The style of the marker. Default is "c0.3c".
            fill (str): The fill color of the marker. Default is "red".
        """
        self.figure.plot(x=x, y=y, style=style, fill=fill)

    def add_colorbar(self, frame=["a2000", "x+lElevation", "y+lm"]):
        """
        Adds a colorbar to the map to indicate elevation values.

        Parameters:
            frame (list): Customization options for the colorbar. Default shows elevation in meters.
        """
        self.figure.colorbar(frame=frame)

    def show(self):
        """
        Displays the figure in an interactive window.
        """
        self.figure.show()

    def save(self, filename="../figs/fig1.png", dpi=400):
        """
        Saves the figure to a file with the specified resolution.

        Parameters:
            filename (str): The path and name of the file to save the figure.
            dpi (int): The resolution in dots per inch (DPI) for the saved figure. Default is 400.
        """
        self.figure.savefig(filename, dpi=dpi)

# IMC map
if __name__ == "__main__":
    # Initialize the plotter with a specific geographical region
    plotter = SRTMMapPlotter(region=[92, 170, -20, 20])
    # Plot the Earth relief map
    plotter.plot_map()
    # Add a marker to the map
    plotter.plot_marker(x=116.708611, y=-0.973056)
    # Add a colorbar to the map
    plotter.add_colorbar()
    # Display the map
    plotter.show()
    # Save the map to a file
    plotter.save()











df = pd.read_csv("../data/all_data.csv", index_col="Date",
                parse_dates=True)


print(df.head())


print(df.info())


print(df.describe())





class SeasonalPlotter:
    """
    A utility class for plotting seasonal trends in a pandas DataFrame. 
    This class is designed to help visualize monthly trends in data over time.
    """

    def __init__(self, dataframe):
        """
        Initializes the SeasonalPlotter with a pandas DataFrame.

        Parameters:
        - dataframe: pandas DataFrame containing the data to be analyzed and plotted.
        """
        try:
            self.dataframe = dataframe
            dataframe.head()  # Try accessing the DataFrame to ensure it's valid.
        except Exception as e:
            print(f"Initialization failed: {e}")
            raise ValueError("Invalid DataFrame provided.") from e

    def plot_seasonal_monthly(self, column_name, title, x_label, y_label, color, save_path=None, dpi=300):
        """
        Plots the monthly seasonal trend of a specified column from the DataFrame.

        Parameters:
        - column_name: The name of the column to analyze and plot.
        - title: The title of the plot.
        - x_label: Label for the x-axis.
        - y_label: Label for the y-axis.
        - color: Color of the bars in the barplot.
        - save_path (optional): The file path to save the plot image. If None, the plot is not saved.
        - dpi (optional): The resolution of the saved plot image. Defaults to 300 DPI.
        
        This method prints out the month with the minimum and maximum average values of the specified column 
        and generates a bar plot showing the average value of the specified column for each month to identify seasonal trends.
        """
        try:
            # Ensure the column exists
            if column_name not in self.dataframe.columns:
                raise ValueError(f"Column '{column_name}' not found in DataFrame.")

            # Resample to monthly averages
            monthly_avg = self.dataframe[column_name].resample('M').mean()
            
            # Create a DataFrame for plotting, including a 'Month' column for the x-axis
            plot_data = pd.DataFrame({column_name: monthly_avg})
            plot_data['Month'] = plot_data.index.month  # Extract month for seasonal plotting
            
            # Group by month to calculate the average value for each month
            seasonal_trends = plot_data.groupby('Month')[column_name].mean()
            
            # Find and print the min and max monthly averages
            min_month = seasonal_trends.idxmin()
            max_month = seasonal_trends.idxmax()
            print(f"Month with minimum average value: {min_month} ({seasonal_trends.min():.2f})")
            print(f"Month with maximum average value: {max_month} ({seasonal_trends.max():.2f})")
            
            # Plotting
            plt.figure(figsize=(10, 6))
            sns.barplot(x=seasonal_trends.index, y=seasonal_trends, color=color)
            plt.title(title)
            plt.xlabel(x_label, fontsize=15)
            plt.ylabel(y_label, fontsize=15)
            plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
            
            # Save the figure if a save path is provided
            if save_path:
                plt.savefig(save_path, dpi=dpi)
                print(f"Figure saved to {save_path} at {dpi} DPI.")
            
            plt.show()
        except Exception as e:
            print(f"Failed to plot seasonal monthly trends: {e}")


season_plot = SeasonalPlotter(df)


season_plot.plot_seasonal_monthly(
    column_name='Chlorophyll_a', 
    title=' ', 
    x_label='Month', 
    y_label='Chlorophyll-a [mg/m$^3$]',
    color='#5aad65',
    save_path='../figs/fig2b.png',
    dpi=400
)





chl = df["Chlorophyll_a"]


chl.head()


print(chl.info())


print(chl.describe())


# HABs events
top_two = chl.nlargest(2)
print("The two maximum Chlorophyll_a values and their dates are:")
for date, value in top_two.items():
    print(f"{value} mg/m^3 on {date.date()}")


fig, ax = plt.subplots(figsize=(12, 8))
ax.plot(chl.index, chl.values, marker="o")  
ax.set_xlabel("Time [days]", fontsize=20)
ax.set_ylabel("Chlorophyll-a [mg/m$^3$]", fontsize=20)
plt.savefig('../figs/fig2a.png', dpi=400)
plt.show()


# HABs events
top_two = chl.nlargest(2)
print("The two maximum Chlorophyll_a concentrations:")
for date, value in top_two.items():
    print(f"{value} mg/m^3 on {date.date()}")


class TimeSeriesAnalysis:
    def __init__(self, series: pd.Series):
        """
        Initialize the TimeSeriesAnalysis with a Pandas Series.
        
        :param series: Pandas Series containing the time series data.
        """
        self.series = series

    def print_skewness_kurtosis(self) -> None:
        """
        Calculate and print skewness and kurtosis of the series.
        """
        try:
            skewness = stats.skew(self.series)
            kurtosis = stats.kurtosis(self.series)
            print(f"\nSkewness: {skewness}\nKurtosis: {kurtosis}")
            print("Interpretation: ", end="")
            print("The distribution is " + ("symmetric." if skewness == 0 else "skewed."))
            print("The distribution has " + ("less " if kurtosis < 0 else "excess ") + "kurtosis compared to a normal distribution.")
        except Exception as e:
            print(f"An error occurred while calculating skewness and kurtosis: {e}")
            
    def interpret_normality_tests(self) -> None:
        """
        Perform and interpret Shapiro-Wilk and D'Agostino's K^2 normality tests.
        """
        try:
            print("Normality Tests Interpretation:")
            shapiro_stat, shapiro_p = stats.shapiro(self.series)
            print(f"Shapiro-Wilk Test: Statistic={round(shapiro_stat, 3)}, p-value={round(shapiro_p, 3)}. " +
                  ("Data is not normally distributed." if shapiro_p < 0.05 else "Data follows a normal distribution."))
            
            dagostino_stat, dagostino_p = stats.normaltest(self.series)
            print(f"D’Agostino’s K^2 Test: Statistic={round(dagostino_stat, 3)}, p-value={round(dagostino_p, 3)}. " +
                  ("Data is not normally distributed." if dagostino_p < 0.05 else "Data follows a normal distribution."))
        except Exception as e:
            print(f"An error occurred during normality tests: {e}")

    def interpret_stationarity_tests(self) -> None:
        """
        Perform and interpret ADF and KPSS stationarity tests.
        """
        try:
            print("\nStationarity Tests Interpretation:")
            adf_result = adfuller(self.series, autolag='AIC')
            adf_stat, adf_p = adf_result[0], adf_result[1]
            print(f"ADF Test: Statistic={round(adf_stat, 3)}, p-value={round(adf_p, 3)}. " +
                  ("Series is stationary." if adf_p < 0.05 else "Series is not stationary."))
            
            kpss_result = kpss(self.series, regression='c')
            kpss_stat, kpss_p = kpss_result[0], kpss_result[1]
            print(f"KPSS Test: Statistic={round(kpss_stat, 3)}, p-value={round(kpss_p, 3)}. " +
                  ("Series is stationary." if kpss_p >= 0.05 else "Series is not stationary."))
        except Exception as e:
            print(f"An error occurred during stationarity tests: {e}")

    def plot_distribution_with_kde(self, filename: str = '../figs/fig2c.png') -> None:
        """
        Plot the distribution of the series with KDE and save to a file.
        Additionally, shows the plot.
        
        :param filename: Filename to save the plot.
        """
        try:
            fig, ax = plt.subplots(figsize=(12, 8))
            sns.histplot(self.series, kde=True, bins=15, ax=ax)
            ax.set_xlabel('Chlorophyll-a [mg/m$^3$]', fontsize=20)
            ax.set_ylabel('Probability Density', fontsize=20)
            plt.savefig(filename)
            plt.show()
            plt.close()
        except Exception as e:
            print(f"An error occurred while generating the KDE plot: {e}")

    def plot_acf_pacf(self, filename: str = '../figs/fig2d.png') -> None:
        """
        Plot ACF and PACF and save to a file. Additionally, shows the plot.
        
        :param filename: Filename to save the plot.
        """
        try:
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            plot_acf(self.series, ax=ax1)
            ax1.set_title("Autocorrelation Function", fontsize=30)
            plot_pacf(self.series, ax=ax2)
            ax2.set_title("Partial Autocorrelation Function", fontsize=30)
            plt.savefig(filename)
            plt.show()
            plt.close()
        except Exception as e:
            print(f"An error occurred while generating ACF and PACF plots: {e}")


analysis = TimeSeriesAnalysis(chl)


analysis.print_skewness_kurtosis()


analysis.interpret_normality_tests()


analysis.interpret_normality_tests()


analysis.plot_distribution_with_kde()


analysis.plot_acf_pacf()





class ExtChlorophyllModel:
    """
    A class to model and analyze extreme chlorophyll-a concentrations using Event Analysis.

    Attributes:
        data (DataFrame): The dataset containing chlorophyll-a concentrations.
        model (EVA object): The extreme value analysis model object.
        summary_bm (DataFrame): Summary of block maxima and return periods.
        extremes (DataFrame): Identified extreme events.
        return_periods (DataFrame): Calculated return periods for extreme events.
    """

    def __init__(self, data):
        """
        Initializes the ExtChlorophyllModel with chlorophyll-a data.

        Parameters:
            data (DataFrame): The dataset containing chlorophyll-a concentrations.
        """
        self.data = data
        self.model = None
        self.summary_bm = None
        self.extremes = None
        self.return_periods = None

    def specify_model(self, block_size="14D"):
        """
        Specifies the extreme value analysis model with given parameters.

        Parameters:
            block_size (str): The size of the block for block maxima method. Defaults to "14D".
        """
        try:
            # Assuming EVA and get_extremes are defined elsewhere
            self.model = EVA(data=self.data)
            self.model.get_extremes(method="BM", extremes_type="high", block_size=block_size, errors="ignore")
        except Exception as e:
            print(f"Error specifying model: {e}")

    def fit_and_plot_model(self):
        """
        Fits the specified model using the Emcee sampler, prints the model summary,
        and plots the extremes and the Markov Chain Monte Carlo (MCMC) traces.
        """
        try:
            # Fit model
            self.model.fit_model(model='Emcee', n_walkers=500, n_samples=2500)
            print(self.model)
            
            # Plot Block Maxima
            fig, ax = self.model.plot_extremes(figsize=(12, 8))
            ax.set_xlabel('Time [days]', fontsize=20)
            ax.set_ylabel('Chlorophyll-a [mg/m$^3$]', fontsize=20)
            fig.tight_layout()
            plt.show()  # Display the figure
            fig.savefig('../figs/fig3a.png', dpi=400)  # Save the figure

            # Plot MCMC trace figures
            fig, ax = self.model.plot_trace(figsize=(15, 8))
            fig.tight_layout()
            plt.show()
            fig.savefig('../figs/fig3b.png', dpi=400)

            fig, ax = self.model.plot_corner(figsize=(15, 15), levels=10)
            fig.tight_layout()
            plt.show()# plot map
            fig.savefig('../figs/fig3c.png', dpi=400)
        except Exception as e:
            print(f"Error fitting and plotting model: {e}")

    def summarize_and_save(self):
        """
        Generates a summary of block maxima and return periods, and saves it to CSV.
        Additionally, computes and saves extreme event return periods.
        """
        try:
            self.summary_bm = self.model.get_summary(return_period=[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000],
                                                     alpha=0.95, n_samples=1000)
            self.summary_bm.to_csv('../data/bm_rp_sum.csv')
            
            self.extremes = get_extremes(ts=self.data, method="BM", block_size="14D")
            self.return_periods = get_return_periods(ts=self.data, extremes=self.extremes, extremes_method="BM", 
                                                     extremes_type="high", block_size="14D",
                                                     return_period_size="14D", plotting_position="weibull")

            rp = self.return_periods.sort_values("return period", ascending=False)
            rp.to_csv('../data/high_return_periods.csv')

            print(rp.sort_values("return period", ascending=False).head())  # Display 5 most extreme cases
        except Exception as e:
            print(f"Error summarizing and saving data: {e}")

    def plot_diagnostic_figures(self):
        """
        Plots diagnostic figures for the extreme value analysis, including return period plots,
        probability density functions, and Q-Q plots.
        """
        try:
            fig, ax = self.model.plot_diagnostic(alpha=0.95, figsize=(18,12))

            # Adjusting figure aesthetics for readability
            for a in fig.axes:
                a.set_title(' ')
            fig.axes[0].set_xlabel('Return Period', fontsize=20)
            fig.axes[0].set_ylabel('Chlorophyll-a [mg/m$^3$]', fontsize=20)
            fig.axes[1].set_xlabel('Chlorophyll-a [mg/m$^3$]', fontsize=20)
            fig.axes[1].set_ylabel('Probability Density', fontsize=20)
            fig.axes[2].set_xlabel('Theoretical', fontsize=20)
            fig.axes[2].set_ylabel('Observed', fontsize=20)
            fig.axes[3].set_xlabel('Theoretical', fontsize=20)
            fig.axes[3].set_ylabel('Observed', fontsize=20)

            sns.despine(left=True)
            plt.show()
            fig.savefig('../figs/fig4.png')
        except Exception as e:
            print(f"Error plotting diagnostic figures: {e}")


ext_chl_model = ExtChlorophyllModel(data=chl)


# Initialize the model with the dataset
ext_chl_model = ExtChlorophyllModel(data=chl)


# Specify the model with desired parameters
ext_chl_model.specify_model(block_size="14D")


# Fit the model and plot the extremes and MCMC traces
ext_chl_model.fit_and_plot_model()


# Generate and save the summary of block maxima and return periods, and compute return periods for extremes
ext_chl_model.summarize_and_save()


# Plot diagnostic figures for the extreme value analysis
ext_chl_model.plot_diagnostic_figures()








class AutoGluonWorkflow:
    """
    This class encapsulates the workflow for training and evaluating a machine learning model
    using AutoGluon's TabularPredictor for a given tabular dataset.
    """

    def __init__(self, data_path, save_path):
        """
        Initializes the workflow with the dataset path and the path to save trained models.

        Parameters:
        - data_path (str): The file path to the dataset.
        - save_path (str): The directory path to save the trained models and their artifacts.
        """
        self.data_path = data_path
        self.save_path = save_path
        self.predictor = None 

    def load_and_prepare_data(self):
        """
        Loads the dataset from the specified path and performs initial preprocessing, such as
        removing unnecessary columns.

        Returns:
        - A pandas DataFrame with the processed dataset or None if an error occurs.
        """
        try:
            data = TabularDataset(self.data_path)
            data.drop(columns='Date', inplace=True)  # Assuming 'Date' column is not needed
            return data
        except Exception as e:
            print(f"Failed to load or preprocess data: {e}")
            return None

    def split_data(self, data):
        """
        Splits the data into training and test sets.

        Parameters:
        - data (pd.DataFrame): The preprocessed dataset.

        Returns:
        - A tuple containing the training and test data as pandas DataFrames.
        """
        try:
            train_size = round(0.8 * len(data))
            train_data = data.sample(train_size, random_state=128)
            test_data = data.drop(train_data.index)
            return train_data, test_data
        except Exception as e:
            print(f"Failed to split data: {e}")
            return None, None

    def train_and_evaluate(self, train_data, test_data):
        """
        Trains a machine learning model using AutoGluon's TabularPredictor on the training data
        and evaluates its performance on the test set. It also calculates and prints feature
        importances.

        Parameters:
        - train_data (pd.DataFrame): The training dataset.
        - test_data (pd.DataFrame): The test dataset.
        """
        try:
            # Training the model
            self.predictor = TabularPredictor(label="Chlorophyll_a", path=self.save_path).fit(train_data)
            
            # Displaying the leaderboard of models
            leaderboard = self.predictor.leaderboard()
            leaderboard.to_csv("../data/devel_leaderboard.csv", index=False)
            print(leaderboard)

            # Evaluating the model on the test set
            y_test = test_data["Chlorophyll_a"]
            test_features = test_data.drop(columns=["Chlorophyll_a"])
            y_pred = self.predictor.predict(test_features)
            metrics = self.predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)

            # Printing evaluation metrics with three decimal precision
            for key, value in metrics.items():
                print(f"{key}: {value:.3f}")

            # Calculating and printing feature importances
            feature_importance = self.predictor.feature_importance(test_data)
            feature_importance.to_csv("../data/devel_features_imp.csv", index=False)
            print(feature_importance)
        except Exception as e:
            print(f"Failed to train or evaluate the model: {e}")

    def get_predictor(self):
        """
        Returns the TabularPredictor instance used for training the model.

        Returns:
        - The TabularPredictor instance or None if the predictor is not yet initialized.
        """
        return self.predictor

if __name__ == "__main__":
    ag_workflow = AutoGluonWorkflow("../data/all_data.csv", "../autogluon_models/trained_models")
    data = ag_workflow.load_and_prepare_data()
    if data is not None:
        train_data, test_data = ag_workflow.split_data(data)
        if train_data is not None and test_data is not None:
            ag_workflow.train_and_evaluate(train_data, test_data)
            predictor = ag_workflow.get_predictor()





# Load previously trained data
new_predictor = TabularPredictor.load("../autogluon_models/trained_models")

# Refit model to test data also for deployment
new_predictor.refit_full() 

# Save final model for deployment
new_predictor.clone_for_deployment('../autogluon_models/final_model_for_deployment')
